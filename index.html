<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-03-03 Mon 09:43 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org2d0fc66">1. About this project</a></li>
<li><a href="#org4d2278b">2. Imports</a></li>
<li><a href="#org0ac144f">3. Functions</a></li>
<li><a href="#orge308b1a">4. Main</a></li>
<li><a href="#org85ba078">5. Conclusions</a></li>
<li><a href="#orgfd95abe">6. Plots</a></li>
<li><a href="#org5703ca6">7. References</a></li>
<li><a href="#org810a676">8. To Do Later</a></li>
</ul>
</div>
</div>
<div id="outline-container-org2d0fc66" class="outline-2">
<h2 id="org2d0fc66"><span class="section-number-2">1.</span> About this project</h2>
<div class="outline-text-2" id="text-1">
<p>
This project uses Convolutional Neural Networks to classify
images. Our dataset is called EuroSAT and there is a paper about it
called "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land
Use and Land Cover Classification" <a href="https://github.com/phelber/EuroSAT">here</a>. Basically we will copy the
method of the paper.
</p>

<p>
We will use the pretrained base <code>resnet50</code> and other goodies from
<code>keras</code> like callbacks and data augmentation layers. We also use
<code>matplotlib</code> for basic plots and <code>numpy</code> for data structures.
</p>

<p>
An outline of the program (about 150 lines of <code>python</code> code) :
</p>
<ul class="org-ul">
<li><code>import</code> statements.</li>
<li>Define some functions for repetitive things.</li>
<li><code>main()</code> function that has the main thought process of training the
model.</li>
</ul>

<p>
We used <a href="https://colab.research.google.com">Google Colab</a> to run these experiments because we do not have
GPU access on our personal computer. We paid for the Pro option
because the free option is unreliable.
</p>

<p>
The EuroSAT dataset is a collection of 27.000 satellite images taken
above European countries. Every image is 64 by 64 pixels and every
pixel can be red, green, or blue (RGB). So every data point has shape
(64, 64, 3). We chose this dataset because of the small size.
</p>

<p>
There are ten possible output classes :
</p>
<ul class="org-ul">
<li>Industrial Building.</li>
<li>Residential Building.</li>
<li>Annual Crop.</li>
<li>Permanent Crop.</li>
<li>River.</li>
<li>Sea and Lake.</li>
<li>Herbaceous Vegetation.</li>
<li>Highway.</li>
<li>Pasture.</li>
<li>Forest.</li>
</ul>

<p>
Our job is to find the right class for every image.
</p>
</div>
</div>
<div id="outline-container-org4d2278b" class="outline-2">
<h2 id="org4d2278b"><span class="section-number-2">2.</span> Imports</h2>
<div class="outline-text-2" id="text-2">
<p>
Let's import some tools for image classification.
</p>

<p>
<code>resnet50</code> is our pretrained base model. It is powerful and saves us
from designing the architecture ourselves.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> keras.applications <span style="color: #a020f0;">import</span> resnet50
</pre>
</div>
<p>
<code>EarlyStopping</code> and <code>ReduceLROnPlateau</code> are essentially forms of
regularization.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> keras.callbacks <span style="color: #a020f0;">import</span> EarlyStopping, ReduceLROnPlateau
</pre>
</div>
<p>
We don't really know what <code>HeNormal</code> does but it stays.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> keras.initializers <span style="color: #a020f0;">import</span> HeNormal
</pre>
</div>
<p>
In order :
</p>
<ul class="org-ul">
<li><code>Dense</code> layers are basic Neural Network layers and we use one as a
hat to sit on top of the <code>resnet50</code> base model. Another one is used
to pick one of eleven classes.</li>
<li><code>Dropout</code> is used as regularization to make the training process
smooth.</li>
<li><code>Flatten</code> is used before <code>Dropout</code> and classification by the <code>Dense</code>
layer.</li>
<li><code>IntegerLookup</code> is for one-hot-encoding the outputs which are
categorical.</li>
<li><code>RandomBrightness</code>, <code>RandomConstrast</code>, and <code>RandomFlip</code> are data
augmentation layers used to make more data than what we are given.</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> keras.layers <span style="color: #a020f0;">import</span> (Dense, Dropout, Flatten, IntegerLookup,
                          RandomBrightness, RandomContrast,
                          RandomFlip)
</pre>
</div>
<p>
<code>CategoricalCrossentropy</code> is our loss function and
<code>CategoricalAccuracy</code> is our metric which we track. We use the <code>Adam</code>
optimizer but any optimizer can be used as long as the relevant
parameters are adjusted.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> keras.losses <span style="color: #a020f0;">import</span> CategoricalCrossentropy
<span style="color: #a020f0;">from</span> keras.metrics <span style="color: #a020f0;">import</span> CategoricalAccuracy
<span style="color: #a020f0;">from</span> keras.optimizers <span style="color: #a020f0;">import</span> Adam
<span style="color: #a020f0;">from</span> keras <span style="color: #a020f0;">import</span> models
</pre>
</div>
<p>
Occasionally we will need to round a <code>float</code> down to an <code>int</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> math <span style="color: #a020f0;">import</span> floor
</pre>
</div>
<p>
Let's get <code>keras</code>, <code>matplotlib</code>, <code>numpy</code>, <code>tensorflow</code>, and
<code>tensorflow_datasets</code>.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">import</span> keras
<span style="color: #a020f0;">import</span> matplotlib.pyplot <span style="color: #a020f0;">as</span> plt
<span style="color: #a020f0;">import</span> numpy <span style="color: #a020f0;">as</span> np
<span style="color: #a020f0;">import</span> tensorflow <span style="color: #a020f0;">as</span> tf
<span style="color: #a020f0;">import</span> tensorflow_datasets <span style="color: #a020f0;">as</span> tfds
</pre>
</div>
</div>
</div>
<div id="outline-container-org0ac144f" class="outline-2">
<h2 id="org0ac144f"><span class="section-number-2">3.</span> Functions</h2>
<div class="outline-text-2" id="text-3">
<p>
This function builds the model by applying the three data augmentation
layers <code>RandomFlip</code>, <code>RandomBrightness</code>, and <code>RandomContrast</code> to the
input. Then we feed the input into the base which is <code>resnet50</code>. We
<code>Flatten</code> and <code>Dropout</code>, then train our own <code>Dense</code> layer with 512
units and get the output by a second <code>Dense</code> layer with eleven
possible outputs. There are eleven outputs and not ten because the
<code>IntegerLookup</code> layer considers the possibility that the output may be
outside the vocabulary.
</p>

<p>
The <code>param_dict</code> argument will be defined later as a dictionary of
tunable parameters. At the moment there is only one parameter, <code>"lr"</code>,
or learning rate.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">build_model</span>(param_dict, base):
    <span style="color: #483d8b;">input</span> = keras.Input(shape=(64, 64, 3))

    <span style="color: #a0522d;">x</span> = RandomFlip()(<span style="color: #483d8b;">input</span>)
    <span style="color: #a0522d;">x</span> = RandomBrightness(0.5)(x)
    <span style="color: #a0522d;">x</span> = RandomContrast(0.5)(x)
    <span style="color: #a0522d;">x</span> = base(x)
    <span style="color: #a0522d;">x</span> = Flatten()(x)
    <span style="color: #a0522d;">x</span> = Dropout(0.1)(x)
    <span style="color: #a0522d;">x</span> = Dense(512, activation=<span style="color: #8b2252;">"relu"</span>, kernel_initializer=HeNormal())(x)

    <span style="color: #a0522d;">output</span> = Dense(11, activation=<span style="color: #8b2252;">"softmax"</span>)(x)

    <span style="color: #a0522d;">model</span> = keras.Model(<span style="color: #483d8b;">input</span>, output)
    model.<span style="color: #483d8b;">compile</span>(optimizer=Adam(learning_rate=param_dict[<span style="color: #8b2252;">"lr"</span>]),
                  loss=CategoricalCrossentropy(),
                  metrics=[CategoricalAccuracy()])

    <span style="color: #a020f0;">return</span> model
</pre>
</div>
<p>
This function returns the callbacks. The <code>EarlyStopping</code> callback will
stop the training process if <code>monitor</code> does not improve after
<code>patience</code> epochs. The <code>ReduceLROnPlateau</code> callback will multiply the
learning rate by <code>factor</code> if <code>monitor</code> does not improve after
<code>patience</code> epochs. These are basic but effective.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">get_callbacks</span>():
    <span style="color: #a0522d;">early_stop_loss</span> = EarlyStopping(monitor=<span style="color: #8b2252;">"loss"</span>, patience=8)
    <span style="color: #a0522d;">reduce_lr_plateau</span> = ReduceLROnPlateau(monitor=<span style="color: #8b2252;">"loss"</span>, factor=0.9,
                                          patience=4)

    <span style="color: #a020f0;">return</span> [early_stop_loss, reduce_lr_plateau]
</pre>
</div>
<p>
This function loads the EuroSAT dataset as one big batch and gives us
the <code>images</code> and <code>labels</code> separately.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">get_eurosat_dataset</span>():
    <span style="color: #a0522d;">images</span>, <span style="color: #a0522d;">labels</span> = tfds.load(<span style="color: #8b2252;">"eurosat"</span>, split=<span style="color: #8b2252;">"train"</span>,
                               as_supervised=<span style="color: #008b8b;">True</span>, batch_size=-1)

    <span style="color: #a020f0;">return</span> images, labels
</pre>
</div>
<p>
This function takes a number and returns the <code>param_dict</code> mentioned
earlier with parameters taking a random value within +-10% of the
original value. We also print the values for something to look at
while training.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">get_random_numbers</span>(middle):
    <span style="color: #a0522d;">rng</span> = np.random.default_rng()
    <span style="color: #a0522d;">param_dict</span> = {<span style="color: #8b2252;">"lr"</span>: middle * (0.9 + 0.2 * rng.random())}
    <span style="color: #483d8b;">print</span>(param_dict)

    <span style="color: #a020f0;">return</span> param_dict
</pre>
</div>
<p>
This function makes the plots and labels the axes. We want to know
about loss and accuracy during training and validation. There is a
<code>start_at</code> variable which tells the plot to skip the first few
values because the first few values are usually much smaller than the
later ones. Training loss and accuracy are blue dots and validation
loss and accuracy are blue x's. We use two different shapes to make
sure colorblind people can interpret the plots.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">plot</span>(history):
    <span style="color: #a0522d;">acc</span> = history.history[<span style="color: #8b2252;">"categorical_accuracy"</span>]
    <span style="color: #a0522d;">loss</span> = history.history[<span style="color: #8b2252;">"loss"</span>]
    <span style="color: #a0522d;">val_acc</span> = history.history[<span style="color: #8b2252;">"val_categorical_accuracy"</span>]
    <span style="color: #a0522d;">val_loss</span> = history.history[<span style="color: #8b2252;">"val_loss"</span>]

    <span style="color: #a0522d;">epochs</span> = <span style="color: #483d8b;">range</span>(<span style="color: #483d8b;">len</span>(loss))
    <span style="color: #a0522d;">start_at</span> = 2

    plt.plot(epochs[start_at:], loss[start_at:], <span style="color: #8b2252;">"ob"</span>,
             label=<span style="color: #8b2252;">"Training Loss"</span>)
    plt.plot(epochs[start_at:], val_loss[start_at:], <span style="color: #8b2252;">"xb"</span>,
             label=<span style="color: #8b2252;">"Validation Loss"</span>)
    plt.title(<span style="color: #8b2252;">"Loss"</span>)
    plt.xlabel(<span style="color: #8b2252;">"Epochs"</span>)
    plt.ylabel(<span style="color: #8b2252;">"Loss"</span>)
    plt.legend()
    plt.show()

    plt.plot(epochs[start_at:], acc[start_at:], <span style="color: #8b2252;">"ob"</span>,
             label=<span style="color: #8b2252;">"Training Accuracy"</span>)
    plt.plot(epochs[start_at:], val_acc[start_at:], <span style="color: #8b2252;">"xb"</span>,
             label=<span style="color: #8b2252;">"Validation Accuracy"</span>)
    plt.title(<span style="color: #8b2252;">"Accuracy"</span>)
    plt.xlabel(<span style="color: #8b2252;">"Epochs"</span>)
    plt.ylabel(<span style="color: #8b2252;">"Accuracy"</span>)
    plt.legend()
    plt.show()

</pre>
</div>
</div>
</div>
<div id="outline-container-orge308b1a" class="outline-2">
<h2 id="orge308b1a"><span class="section-number-2">4.</span> Main</h2>
<div class="outline-text-2" id="text-4">
<p>
A rough outline of the <code>main()</code> function :
</p>
<ul class="org-ul">
<li>Get EuroSAT dataset.</li>
<li>Get <code>resnet50</code> pretrained base.</li>
<li>One-hot-encode labels.</li>
<li>Train top layers of model.</li>
<li>Fine-tune whole model.</li>
<li>Get predictions on test data.</li>
<li>And other housekeeping items scattered here and there.</li>
</ul>
<p>
The <code>main()</code> function calls the shots.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">def</span> <span style="color: #0000ff;">main</span>():
</pre>
</div>
<p>
We begin by loading the dataset.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">images</span>, <span style="color: #a0522d;">labels</span> = get_eurosat_dataset()
</pre>
</div>
<p>
We get a list of percentile indices for easy dataset splitting later.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">percents</span> = [floor(np.shape(images)[0] * (i / 100.0))
            <span style="color: #a020f0;">for</span> i <span style="color: #a020f0;">in</span> <span style="color: #483d8b;">range</span>(100)]
</pre>
</div>
<p>
Let's load the <code>resnet50</code> base and freeze the layers. We will unfreeze
the layers later as the paper says to do.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">base</span> = resnet50.ResNet50(include_top=<span style="color: #008b8b;">False</span>, input_shape=(64, 64, 3))
base.<span style="color: #a0522d;">trainable</span> = <span style="color: #008b8b;">False</span>
</pre>
</div>
<p>
Vocabulary for the ten output classes.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">label_vocab</span> = [i <span style="color: #a020f0;">for</span> i <span style="color: #a020f0;">in</span> <span style="color: #483d8b;">range</span>(10)]
</pre>
</div>
<p>
One-hot-encode the labels using the vocabulary from above.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">one_hot_encode_layer</span> = IntegerLookup(vocabulary=label_vocab,
                                     output_mode=<span style="color: #8b2252;">"one_hot"</span>)
<span style="color: #a0522d;">encoded_labels</span> = one_hot_encode_layer(labels)
</pre>
</div>
<p>
We split the dataset into an 80-20 (Training-Test) split.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">split</span> = 80
<span style="color: #a0522d;">train_images</span> = images[:percents[split]]
<span style="color: #a0522d;">test_images</span> = images[percents[split]:]
<span style="color: #a0522d;">train_labels</span> = encoded_labels[:percents[split]]
<span style="color: #a0522d;">test_labels</span> = encoded_labels[percents[split]:]
</pre>
</div>
<p>
Load the callbacks.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">callbacks</span> = get_callbacks()
</pre>
</div>
<p>
Train our two <code>Dense</code> layers first. We use a 10% validation split so
the dataset now has a 72-8-20 (Training-Validation-Test) split. We
shuffle to keep things standard casino operating procedure.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #483d8b;">print</span>(<span style="color: #8b2252;">'Fitting model.'</span>)
<span style="color: #a0522d;">model</span> = build_model(get_random_numbers(0.01), base)
<span style="color: #a0522d;">history</span> = model.fit(train_images, train_labels, batch_size=128,
                    callbacks=callbacks, epochs=64, shuffle=<span style="color: #008b8b;">True</span>,
                    validation_split=0.1, verbose=1)

plot(history)
</pre>
</div>
<p>
Next we set <code>base.trainable</code> to <code>True</code> to unfreeze the base layers but
this time we train with a much smaller learning rate. We don't want
any large disruptions here.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #483d8b;">print</span>(<span style="color: #8b2252;">"Fine-tuning."</span>)
base.<span style="color: #a0522d;">trainable</span> = <span style="color: #008b8b;">True</span>
<span style="color: #a0522d;">model</span> = build_model(get_random_numbers(0.0001), base)
<span style="color: #a0522d;">history</span> = model.fit(train_images, train_labels, batch_size=128,
                    callbacks=callbacks, epochs=128, shuffle=<span style="color: #008b8b;">True</span>,
                    validation_split=0.1, verbose=1)

plot(history)
</pre>
</div>
<p>
Call the <code>evaluate()</code> function with <code>test_images</code> and <code>test_labels</code> to
see how we did. Hopefully our final results here are very close to our
earlier validation results.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #483d8b;">print</span>(<span style="color: #8b2252;">"Predicting."</span>)
model.evaluate(test_images, test_labels, verbose=1)
</pre>
</div>
<p>
These lines go at the end outside of the <code>main()</code> function's
indentation level.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">if</span> <span style="color: #483d8b;">__name__</span> == <span style="color: #8b2252;">"__main__"</span>:
    main()
</pre>
</div>
</div>
</div>
<div id="outline-container-org85ba078" class="outline-2">
<h2 id="org85ba078"><span class="section-number-2">5.</span> Conclusions</h2>
<div class="outline-text-2" id="text-5">
<p>
At this point after running the program a few times we see that our
model gets about 96% test accuracy. The plots for accuracy and loss
show that our training process is pretty sound. We may do some further
analysis with a confusion matrix or something else to figure out which
images we are still misclassifying. The benchmark from the paper is
about 98.5% test accuracy with an 80-20 split using the <code>resnet50</code>
base. We are satisfied for now with 96%.
</p>
</div>
</div>
<div id="outline-container-orgfd95abe" class="outline-2">
<h2 id="orgfd95abe"><span class="section-number-2">6.</span> Plots</h2>
<div class="outline-text-2" id="text-6">

<div id="orge744ac8" class="figure">
<p><img src="./train-loss.png" alt="train-loss.png" />
</p>
<p><span class="figure-number">Figure 1: </span>Loss when training top few layers.</p>
</div>

<div id="org96d4143" class="figure">
<p><img src="./train-acc.png" alt="train-acc.png" />
</p>
<p><span class="figure-number">Figure 2: </span>Accuracy when training top few layers.</p>
</div>

<div id="org27a3353" class="figure">
<p><img src="./finetune-loss.png" alt="finetune-loss.png" />
</p>
<p><span class="figure-number">Figure 3: </span>Loss when fine-tuning whole model.</p>
</div>

<div id="orge055a63" class="figure">
<p><img src="./finetune-acc.png" alt="finetune-acc.png" />
</p>
<p><span class="figure-number">Figure 4: </span>Accuracy when fine-tuning whole model.</p>
</div>
</div>
</div>
<div id="outline-container-org5703ca6" class="outline-2">
<h2 id="org5703ca6"><span class="section-number-2">7.</span> References</h2>
<div class="outline-text-2" id="text-7">
<ul class="org-ul">
<li>Helber, Patrick and others, "EuroSAT: A Novel Dataset and Deep
Learning Benchmark for Land Use and Land Cover Classification",
<i>IEEE Journal of Selected Topics in Applied Earth Observations and
Remote Sensing</i>, 2017, <a href="https://github.com/phelber/EuroSAT">EuroSAT GitHub</a>.</li>
</ul>
</div>
</div>
<div id="outline-container-org810a676" class="outline-2">
<h2 id="org810a676"><span class="section-number-2">8.</span> To Do Later</h2>
<div class="outline-text-2" id="text-8">
<ul class="org-ul">
<li>Add links.</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2025-03-03 Mon 09:43</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
